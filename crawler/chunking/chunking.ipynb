{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d689cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "! uv pip install langchain langchain-community markitdown[all]  langchain-text-splitters bs4 requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd76d5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! uv pip install -q -U google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f5eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! uv pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6bf4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_markdown_h1(text: str) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    # Xóa các dòng bắt đầu bằng đúng 1 dấu #\n",
    "    return re.sub(\n",
    "        r\"(?m)^\\s{0,3}#\\s+.*$\",\n",
    "        \"\",\n",
    "        text\n",
    "    ).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48beb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from markitdown import MarkItDown\n",
    "\n",
    "def convert_to_markdown(input_filepath):\n",
    "    md = MarkItDown(enable_plugins=False)\n",
    "    result = md.convert(input_filepath)\n",
    "    return result.text_content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1e3430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "load_dotenv()\n",
    "def convert_gemini(text, retry = 3):\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Bạn là một trợ lý chuyên cấu trúc hóa văn bản sang Markdown theo nguyên tắc ngữ nghĩa chặt chẽ.\n",
    "\n",
    "    NHIỆM VỤ:\n",
    "    Chuyển đổi văn bản đầu vào thành Markdown rõ ràng, mạch lạc, hợp lý về mặt ngữ nghĩa.\n",
    "    Tuyệt đối chỉ chỉnh sửa nội dung khi sai chính tả hay ngữ pháp hay có lỗi xuống dòng.\n",
    "    KHÔNG lạm dụng header.\n",
    "    KHÔNG tạo header rỗng hoặc header chỉ để gom nhóm hình thức.\n",
    "\n",
    "    NGUYÊN TẮC CỐT LÕI (BẮT BUỘC):\n",
    "    ❗ Mỗi header phải đại diện cho MỘT khối nội dung hoàn chỉnh.\n",
    "    ❗ Header phải có nội dung trực tiếp đi kèm ngay bên dưới.\n",
    "    ❗ Không được tạo header chỉ để làm nhãn cho các header con.\n",
    "\n",
    "    QUY TẮC CẤP HEADER CƠ BẢN (CHỈ ÁP DỤNG KHI ĐỦ ĐIỀU KIỆN NGỮ NGHĨA):\n",
    "    - I, II, III, … → ##\n",
    "    - 1, 2, 3, … → ###\n",
    "    - a, b, c, … → ####\n",
    "\n",
    "    QUY TẮC THEO ĐỘ DÀI & LOẠI THÔNG TIN:\n",
    "    KHÔNG tạo header cho các dòng chỉ là:\n",
    "    - Mốc thời gian (ngày / tháng / năm)\n",
    "    - Sự kiện ngắn gắn với mốc thời gian\n",
    "    - Dòng dạng “Ngày – Sự kiện”\n",
    "    - Các ý song song trong danh sách mục tiêu, nhiệm vụ, tiêu chí\n",
    "\n",
    "    Các dòng này phải được xem là:\n",
    "    → nội dung thuộc cùng một mục\n",
    "    → trình bày dưới dạng đoạn văn hoặc danh sách (numbered list / bullet)\n",
    "\n",
    "    VÍ DỤ KHÔNG ĐƯỢC COI LÀ HEADER:\n",
    "    - 07/09/1953 – Thành lập ...\n",
    "    - Năm 1997: Công bố quyết định ...\n",
    "    - 22/03/1999 Thành lập trung tâm ...\n",
    "    - 1. Phát triển …\n",
    "    - 2. Nâng cao …\n",
    "\n",
    "    QUY TẮC RIÊNG CHO TIMELINE / LỊCH SỬ:\n",
    "    - Nếu một header (## hoặc ###) bao gồm nhiều mốc thời gian liên tiếp:\n",
    "    - Giữ DUY NHẤT header đó\n",
    "    - Toàn bộ mốc thời gian bên trong KHÔNG được đánh header con\n",
    "    - Trình bày các mốc dưới dạng danh sách (-) hoặc đoạn văn\n",
    "\n",
    "    QUY TẮC TẠO HEADER CON:\n",
    "    CHỈ tạo header con khi ĐỒNG THỜI thỏa mãn:\n",
    "    - Header cha có nội dung mô tả riêng, hoàn chỉnh\n",
    "    - Dòng được chọn làm header mang tính khái quát (chủ đề, giai đoạn, phân loại)\n",
    "    - Nội dung bên dưới đủ dài (≥ 3 câu hoặc 3 ý)\n",
    "    - Có khả năng chia tiếp thành các ý độc lập\n",
    "\n",
    "    Nếu KHÔNG chắc chắn:\n",
    "    → Ưu tiên KHÔNG tạo header\n",
    "    → Ưu tiên trình bày dưới dạng nội dung thường\n",
    "\n",
    "    QUY TẮC SUY LUẬN KHI VĂN BẢN KHÔNG RÕ CẤU TRÚC:\n",
    "    - Dòng mang tính bao trùm, khái quát → header\n",
    "    - Dòng mang tính dữ kiện, mô tả, minh họa → nội dung\n",
    "    - Một header chỉ chứa duy nhất 1 dòng sự kiện → hạ cấp thành nội dung\n",
    "    \n",
    "    QUY TẮC BỔ SUNG CHO VĂN BẢN TIN TỨC:\n",
    "\n",
    "    - Mặc định coi toàn bộ bài tin là MỘT document liền mạch.\n",
    "    KHÔNG bắt buộc tạo header.\n",
    "\n",
    "    - CHỈ tạo header (##) khi có một khối ngữ cảnh hoặc nội dung tổng quát\n",
    "    độc lập về mặt ngữ nghĩa, đứng riêng được, và có tối thiểu 3 câu hoặc 3 ý.\n",
    "\n",
    "    -KHÔNG tạo header cho:\n",
    "    + mốc thời gian, lễ ký kết, diễn biến sự kiện\n",
    "    + phát biểu cá nhân, trích dẫn\n",
    "    + chú thích ảnh, danh sách người tham dự\n",
    "    + đoạn PR, nhận định chung, kỳ vọng\n",
    "\n",
    "    -Nếu không chắc chắn việc tạo header có cải thiện cấu trúc ngữ nghĩa\n",
    "    và khả năng chunk dữ liệu → KHÔNG tạo header, giữ nguyên dạng đoạn văn.\n",
    "\n",
    "\n",
    "    KHÔNG ĐƯỢC:\n",
    "    - Để header không có nội dung trực tiếp\n",
    "    - Tạo cấu trúc kiểu:\n",
    "    ## Tiêu đề\n",
    "    ### 1.\n",
    "    ### 2.\n",
    "    - Biến timeline hoặc danh sách mục tiêu thành cây header sâu\n",
    "    - Làm mất nội dung gốc\n",
    "    - Thêm nội dung mới\n",
    "    \n",
    "    ĐẦU VÀO:\n",
    "    {text}\n",
    "\n",
    "    ĐẦU RA:\n",
    "    Chỉ trả về nội dung Markdown đã xử lý.\n",
    "    Không giải thích.\n",
    "    Không nhận xét.\n",
    "\n",
    "    \"\"\"\n",
    "    client = genai.Client(api_key=os.getenv(\"GENAI_API_KEY\"))\n",
    "    while retry > 0:\n",
    "        try:\n",
    "             response = client.models.generate_content(\n",
    "                model=\"gemini-3-flash-preview\", contents=prompt\n",
    "            )\n",
    "             break\n",
    "        except Exception as e:\n",
    "            retry -= 1\n",
    "            if retry == 0:\n",
    "                raise e\n",
    "    markdown_pattern_cell = r'```markdown(.*?)```'\n",
    "    result = re.sub(markdown_pattern_cell, \"\", response.text, flags=re.DOTALL)\n",
    "    result = remove_markdown_h1(result)\n",
    "    print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb4052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleantable_markdown(markdown_text):\n",
    "    \"\"\"Convert markdown tables in `markdown_text` to clean plain-text rows.\n",
    "\n",
    "    - Preserves fenced code blocks (```...```) unchanged.\n",
    "    - Detects markdown tables with a header line containing \"|\" and a following\n",
    "      separator line of dashes/colons (with or without surrounding pipes).\n",
    "    - Replaces each table with its rows where cells are joined by 4 spaces.\n",
    "\n",
    "    Returns the cleaned text.\n",
    "    \"\"\"\n",
    "    if not markdown_text:\n",
    "        return ''\n",
    "\n",
    "    lines = markdown_text.splitlines()\n",
    "    out_lines = []\n",
    "    in_code = False\n",
    "    i = 0\n",
    "\n",
    "    sep_re = re.compile(r'^\\s*\\|?\\s*[:\\-]{1,}\\s*(\\|\\s*[:\\-]{1,}\\s*)+\\|?\\s*$')\n",
    "\n",
    "    def parse_row(r):\n",
    "        cells = [c.strip() for c in r.split('|')]\n",
    "        # remove empty leading/trailing cell if line used surrounding pipes\n",
    "        if cells and cells[0] == '':\n",
    "            cells = cells[1:]\n",
    "        if cells and cells[-1] == '':\n",
    "            cells = cells[:-1]\n",
    "        # join non-empty cells with some spacing\n",
    "        return '    '.join([c for c in cells if c != ''])\n",
    "\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        # toggle fenced code blocks\n",
    "        if line.strip().startswith('```'):\n",
    "            in_code = not in_code\n",
    "            out_lines.append(line)\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        if in_code:\n",
    "            out_lines.append(line)\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # detect markdown table header + separator\n",
    "        if '|' in line and (i + 1) < len(lines) and sep_re.match(lines[i + 1]):\n",
    "            # header\n",
    "            out_lines.append(parse_row(line))\n",
    "            # consume separator\n",
    "            j = i + 2\n",
    "            # following rows while they contain pipe characters\n",
    "            while j < len(lines) and ('|' in lines[j]):\n",
    "                out_lines.append(parse_row(lines[j]))\n",
    "                j += 1\n",
    "            i = j\n",
    "            continue\n",
    "\n",
    "        # otherwise normal line\n",
    "        out_lines.append(line)\n",
    "        i += 1\n",
    "\n",
    "    return '\\n'.join(out_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f494ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def clean_markdown(md: str) -> str:\n",
    "    \"\"\"Clean markdown to plain text for pure textual data (no code, no math).\"\"\"\n",
    "    if not md:\n",
    "        return \"\"\n",
    "\n",
    "    text = unicodedata.normalize(\"NFKC\", md)\n",
    "\n",
    "    # 1. Remove HTML tags\n",
    "    text = re.sub(r\"<[^>]+>\", \" \", text)\n",
    "\n",
    "    # 2. Remove images: ![alt](url) -> alt\n",
    "    text = re.sub(r\"!\\[([^\\]]*)\\]\\([^)]+\\)\", r\"\\1\", text)\n",
    "\n",
    "    # 3. Remove links: [text](url) -> text\n",
    "    text = re.sub(r\"\\[([^\\]]+)\\]\\([^)]+\\)\", r\"\\1\", text)\n",
    "\n",
    "    # 5. Remove blockquotes\n",
    "    text = re.sub(r\"^\\s*>\\s*\", \"\", text, flags=re.MULTILINE)\n",
    "\n",
    "    # 6. Remove list markers (-, *, +)\n",
    "    text = re.sub(r\"^\\s*[-*+]\\s+\", \"\", text, flags=re.MULTILINE)\n",
    "\n",
    "    # 7. Remove emphasis markers (**bold**, *italic*, __bold__, _italic_)\n",
    "    text = re.sub(r\"\\*\\*(.*?)\\*\\*\", r\"\\1\", text)\n",
    "    text = re.sub(r\"\\*(.*?)\\*\", r\"\\1\", text)\n",
    "    text = re.sub(r\"__(.*?)__\", r\"\\1\", text)\n",
    "    text = re.sub(r\"_(.*?)_\", r\"\\1\", text)\n",
    "\n",
    "    # 8. Remove inline code backticks\n",
    "    text = re.sub(r\"`([^`]*)`\", r\"\\1\", text)\n",
    "\n",
    "    # 9. Remove horizontal rules\n",
    "    text = re.sub(r\"^\\s*[-*_]{3,}\\s*$\", \"\", text, flags=re.MULTILINE)\n",
    "\n",
    "    # 10. Replace common HTML entities\n",
    "    text = re.sub(r\"&nbsp;|&amp;|&lt;|&gt;\", \" \", text)\n",
    "\n",
    "    # 11. Normalize whitespace\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "\n",
    "    # 12. Trim lines\n",
    "    text = \"\\n\".join(line.strip() for line in text.splitlines())\n",
    "\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500e04fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "def split_by_recursive(text):\n",
    "    \"\"\"Split text into chunks using RecursiveCharacterTextSplitter.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "        length_function=len,\n",
    "        is_separator_regex=False\n",
    "    )\n",
    "    \n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91790de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "def split_by_markdown_header(markdown_text):\n",
    "    headers_to_split = [\n",
    "        (\"#\",\"Header 1\"),\n",
    "        (\"##\", \"Header 2\"),\n",
    "        (\"###\", \"Header 3\"),\n",
    "        (\"####\", \"Header 4\")\n",
    "    ]\n",
    "    md_headsplitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split,\n",
    "                                          strip_headers=True)\n",
    "    md_header_splits = md_headsplitter.split_text(markdown_text)\n",
    "    return md_header_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4367c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def convert_md_to_text(md: str) -> str:\n",
    "    if not md:\n",
    "        return \"\"\n",
    "\n",
    "    text = unicodedata.normalize(\"NFKC\", md)\n",
    "\n",
    "    text = re.sub(r\"<[^>]+>\", \"\", text)\n",
    "    text = re.sub(r\"```[\\s\\S]*?```\", \"\", text)\n",
    "\n",
    "    # Remove headings ###\n",
    "    text = re.sub(r\"^#{1,6}\\s*\", \"\", text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove blockquotes >\n",
    "    text = re.sub(r\"^\\s*>+\\s?\", \"\", text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove list markers\n",
    "    text = re.sub(r\"^\\s*[-*+]\\s+\", \"\", text, flags=re.MULTILINE)\n",
    "    text = re.sub(r\"^\\s*\\d+\\.\\s+\", \"\", text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove inline formatting\n",
    "    text = re.sub(r\"\\*\\*(.*?)\\*\\*\", r\"\\1\", text)\n",
    "    text = re.sub(r\"\\*(.*?)\\*\", r\"\\1\", text)\n",
    "    text = re.sub(r\"`([^`]*)`\", r\"\\1\", text)\n",
    "    text = re.sub(r\"~~(.*?)~~\", r\"\\1\", text)\n",
    "\n",
    "    # Links\n",
    "    text = re.sub(r\"\\[([^\\]]+)\\]\\([^)]+\\)\", r\"\\1\", text)\n",
    "\n",
    "    # Entities\n",
    "    text = re.sub(r\"&nbsp;|&amp;|&lt;|&gt;\", \" \", text)\n",
    "\n",
    "    # Whitespace\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c818165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_file(filepath: str) -> str:\n",
    "    \"\"\"Extract the file name without extension from a given file path.\"\"\"\n",
    "    base_name = os.path.basename(filepath)\n",
    "    name, _ = os.path.splitext(base_name)\n",
    "    return name.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd322b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def get_data_path():\n",
    "    try:\n",
    "        base = Path(__file__).parent\n",
    "    except NameError:\n",
    "        base = Path.cwd()\n",
    "    data_path = (base / \"data/ptit\").resolve()\n",
    "    if not data_path.exists():\n",
    "        # fallback to workspace-specific data folder (adjust if needed)\n",
    "        data_path = Path(\"d:/crapy/crawler/crawler/chunking/data/ptit\").resolve()\n",
    "    return data_path\n",
    "\n",
    "path = get_data_path()\n",
    "print(\"Using data path:\", path)\n",
    "\n",
    "for file_path in path.iterdir():\n",
    "    print(file_path)\n",
    "    markdown_text = convert_to_markdown(str(file_path))\n",
    "    markdown_text = cleantable_markdown(markdown_text)\n",
    "    markdown_text = convert_gemini(markdown_text)\n",
    "    clean_md = clean_markdown(markdown_text)\n",
    "    markdown_chunks = split_by_markdown_header(clean_md)\n",
    "    file_name = get_name_file(str(file_path))\n",
    "    for chunk in markdown_chunks:\n",
    "        content = convert_md_to_text(chunk.page_content)\n",
    "        # Sửa: dùng .values() để lấy nội dung header thay vì keys\n",
    "        headers = [convert_md_to_text(v).strip() for v in chunk.metadata.values()] if chunk.metadata else []\n",
    "        data = {\n",
    "            \"source\": file_name,\n",
    "            \"content\": content,\n",
    "            \"header\": headers\n",
    "        }\n",
    "        with open(\"data_chunked.json\", \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crapy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
